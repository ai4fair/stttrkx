{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Histograms_\n",
    "\n",
    "- _Hit Distribution_\n",
    "- _Momentum Distribution_\n",
    "- _A.O.B._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import seaborn as sns\n",
    "import trackml.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append parent dir\n",
    "sys.path.append('..')\n",
    "\n",
    "# local imports\n",
    "from src import Compose_Event, Draw_Compose_Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Input Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu- data (old)\n",
    "# input_dir = './data_sets/pandaml/data_3.0_7.0_GeV/'\n",
    "\n",
    "# mu+mu- data (current)\n",
    "input_dir = '../train_quick'\n",
    "\n",
    "# pbarp data (coming)\n",
    "# input_dir = os.environ['HOME']+'/current/2_deepana/pandaml/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find All Input Data Files (hits.csv, cells.csv, particles.csv, truth.csv)\n",
    "all_files = os.listdir(input_dir)\n",
    "all_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract File Prefixes (use e.g. xxx-hits.csv)\n",
    "suffix = '-hits.csv'\n",
    "file_prefixes = sorted(os.path.join(input_dir, f.replace(suffix, '')) for f in all_files if f.endswith(suffix))\n",
    "file_prefixes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of events\n",
    "len(file_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR, Extract File Prefixes (only works if we don't have any additional files e.g. *.root, *.log etc.)\n",
    "all_events = sorted(np.unique([os.path.join(input_dir, event[:15]) for event in all_files]))\n",
    "all_events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of events (in addition to *.csv, *.root and *.log files exists in this dir.)\n",
    "len(all_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch an event, use event_id (int)\n",
    "prefix = \"event{:010d}\".format(event_id)                     # OR, \n",
    "prefix = str('event{!s}'.format(format(event_id, '010d')))   # a little better\n",
    "event_prefix = os.path.join(input_dir, prefix)              # event_prefix ~ event_file = input_dir + prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits, tubes, particles, truth = trackml.dataset.load_event(event_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR, use event_id to fectch one file from list of all files\n",
    "event_prefix = file_prefixes[event_id]\n",
    "print(event_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an event\n",
    "hits, tubes, particles, truth = trackml.dataset.load_event(event_prefix)\n",
    "\n",
    "# memory usage\n",
    "mem_bytes = (hits.memory_usage(index=True).sum() \n",
    "             + tubes.memory_usage(index=True).sum() \n",
    "             + particles.memory_usage(index=True).sum() \n",
    "             + truth.memory_usage(index=True).sum())\n",
    "\n",
    "print('{} memory usage {:.2f} MB'.format(os.path.basename(event_prefix), mem_bytes / 2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.head()\n",
    "# tubes.head()\n",
    "# particles.head()\n",
    "# truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(1) - Detector Layout_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = Compose_Event(event_prefix, selection=False, noise=False, skewed=False)\n",
    "Draw_Compose_Event(event,figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.particle_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = Compose_Event(event_prefix, selection=True, noise=False, skewed=False)\n",
    "Draw_Compose_Event(event,figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.particle_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(2) - Draw Individual Tracks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess hits\n",
    "# hits['r'] = hits.apply(lambda row: np.sqrt(row.x**2 + row.y**2), axis=1)\n",
    "hits_ = hits.assign(r=hits.apply(lambda row: np.sqrt(row.x**2 + row.y**2), axis=1))\n",
    "hits_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have sorted hits, lets draw a single track.\n",
    "data = hits_[truth.particle_id == particles.iloc[1,0]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Object Oriented API\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.scatter(data.x.values, data.y.values)\n",
    "ax.plot(data.x.values, data.y.values, \"-o\")\n",
    "\n",
    "ax.set_title('Single Track')\n",
    "ax.set_xlabel('x [cm]')\n",
    "ax.set_ylabel('y [cm]')\n",
    "# ax.set_xlim(-40, 40)\n",
    "# ax.set_ylim(-40, 40)\n",
    "fig.tight_layout()\n",
    "# fig.savefig('event.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Object Oriented API\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "a, b = np.polyfit(data.x, data.y, 1)\n",
    "y = a*data.x.values + b\n",
    "\n",
    "ax.scatter(data.x.values, data.y.values)\n",
    "ax.plot(data.x.values, y, 'r')\n",
    "ax.set_title('Fitted Line')\n",
    "ax.set_xlabel('x [cm]')\n",
    "ax.set_ylabel('y [cm]')\n",
    "# ax.set_xlim(-40, 40)\n",
    "# ax.set_ylim(-40, 40)\n",
    "fig.tight_layout()\n",
    "# fig.savefig('event.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(3) - Momentum Distributions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate & assign pt\n",
    "particles = particles.assign(pt=np.sqrt(particles.px**2 + particles.py**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pyplot API\n",
    "plt.close('all')\n",
    "plt.style.use('seaborn')\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.hist(particles.pt, bins=10)\n",
    "\n",
    "plt.xlabel('p_t [GeV]')\n",
    "plt.ylabel('counts')\n",
    "# plt.xlim((0.1, 1.5))\n",
    "# plt.ylim((5, 40))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average hits per track\n",
    "print(\"Average number of hits per tracks: {}\".format(hits.hit_id.count()/particles.particle_id.unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Misc._"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# first drop skewed straws. later z-axis\n",
    "# hits.query('skewed==0').head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "truth_s = truth[['tx','ty','tz','tpx','tpy','tpz']]\n",
    "_ = truth_s.hist(figsize = (8,8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "particles_s = particles[['px','py','pz']]\n",
    "_ = particles_s.hist(figsize = (8,8))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pandas: Histogram\n",
    "hits_s = hits[['x', 'y', 'z']]\n",
    "_ = hits_s.hist(color='b', alpha=0.5, bins=50, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get every 3rd particle\n",
    "tracks = truth.particle_id.unique()[1::2]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for track in tracks:\n",
    "    t = truth[truth.particle_id == track]\n",
    "    ax.plot3D(t.tz, t.tx, t.ty)\n",
    "\n",
    "ax.set_xlabel('z (cm)')\n",
    "ax.set_ylabel('x (cm)')\n",
    "ax.set_zlabel('y (cm)')\n",
    "\n",
    "# These two added to widen the 3D space\n",
    "ax.scatter(100,100,100, s=0)\n",
    "ax.scatter(-100,-100,-100, s=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for pid in sel_pids:\n",
    "    ax.scatter(hits[hits.particle_id == pid].x.values, hits[hits.particle_id == pid].y.values, label='track %d'%pid)\n",
    "\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.legend(fontsize=10, loc='best')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load event using trackml.dataset (update: pandaroot will now generate tubes.csv as cells.csv)\n",
    "event_prefix = str('event{!s}'.format(format(event_id, '010d')))\n",
    "prefix = input_dir + str('event{!s}'.format(format(event_id, '010d')))\n",
    "hits, tubes, particles, truth = trackml.dataset.load_event(prefix)\n",
    "\n",
    "mem_bytes = (hits.memory_usage(index=True).sum() \n",
    "             + tubes.memory_usage(index=True).sum() \n",
    "             + particles.memory_usage(index=True).sum() \n",
    "             + truth.memory_usage(index=True).sum())\n",
    "\n",
    "print('{} memory usage {:.2f} MB'.format(event_prefix, mem_bytes / 2**20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
